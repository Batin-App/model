{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7563141,
     "sourceType": "datasetVersion",
     "datasetId": 4403839
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.nn.parallel import DataParallel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:26.652478Z",
     "iopub.execute_input": "2024-05-01T17:02:26.653383Z",
     "iopub.status.idle": "2024-05-01T17:02:36.904576Z",
     "shell.execute_reply.started": "2024-05-01T17:02:26.653337Z",
     "shell.execute_reply": "2024-05-01T17:02:36.903793Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/kaggle/input/emotions/text.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:36.906031Z",
     "iopub.execute_input": "2024-05-01T17:02:36.906438Z",
     "iopub.status.idle": "2024-05-01T17:02:38.076466Z",
     "shell.execute_reply.started": "2024-05-01T17:02:36.906411Z",
     "shell.execute_reply": "2024-05-01T17:02:38.075515Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "execution_count": 2,
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0                                               text  label\n0           0      i just feel really helpless and heavy hearted      4\n1           1  ive enjoyed being able to slouch about relax a...      0\n2           2  i gave up my internship with the dmrg and am f...      4\n3           3                         i dont know i feel so lost      0\n4           4  i am a kindergarten teacher and i am thoroughl...      4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>i just feel really helpless and heavy hearted</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ive enjoyed being able to slouch about relax a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>i gave up my internship with the dmrg and am f...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>i dont know i feel so lost</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>i am a kindergarten teacher and i am thoroughl...</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class TextStratifiedData(Dataset):\n",
    "    def __init__(self, df, length=None):\n",
    "        if length is not None and length > df.shape[0]:\n",
    "            raise ValueError(\"Length parameter cannot be greater than the size of the dataset.\")\n",
    "        self.length = length if length is not None else len(df)\n",
    "        self.df = self.stratify(df)\n",
    " \n",
    "    def stratify(self, df):\n",
    "        min_count = df['label'].value_counts().min()\n",
    "        df = df.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n",
    "        return df.sample(self.length)\n",
    "\n",
    "    def len(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        return self.df.iloc[idx, :]\n",
    "    \n",
    "    def get_all(self):\n",
    "        return self.df\n",
    "    \n",
    "    \n",
    "df = TextStratifiedData(df,25000).get_all()\n",
    "\n",
    "df.label.value_counts()"
   ],
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:38.077665Z",
     "iopub.execute_input": "2024-05-01T17:02:38.077974Z",
     "iopub.status.idle": "2024-05-01T17:02:38.193568Z",
     "shell.execute_reply.started": "2024-05-01T17:02:38.077948Z",
     "shell.execute_reply": "2024-05-01T17:02:38.192680Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_34/3363077029.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df = df.groupby('label').apply(lambda x: x.sample(min_count)).reset_index(drop=True)\n",
     "output_type": "stream"
    },
    {
     "execution_count": 3,
     "output_type": "execute_result",
     "data": {
      "text/plain": "label\n4    4207\n5    4196\n2    4182\n3    4181\n0    4141\n1    4093\nName: count, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts = train_texts.tolist()\n",
    "val_texts = val_texts.tolist()\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels,dtype=torch.float64))\n",
    "val_dataset = torch.utils.data.TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], torch.tensor(val_labels,dtype=torch.float64))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:38.195650Z",
     "iopub.execute_input": "2024-05-01T17:02:38.195976Z",
     "iopub.status.idle": "2024-05-01T17:02:47.286204Z",
     "shell.execute_reply.started": "2024-05-01T17:02:38.195944Z",
     "shell.execute_reply": "2024-05-01T17:02:47.285332Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "971a15bc3ff447e5b911ec09cbf9d6b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca20607de45f418a9c0c6aec90944524"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8819c9e5e12a4dc78cf84c67d0560ceb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ee88fd19b1048d18dbc9fadd12bf71f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8171f7d1769241498c6ea43f2e9d9cf7"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class EmotionClassifierWithConv(nn.Module):\n",
    "    def __init__(self, transformer_model, num_classes, kernel_size=3, num_filters=256):\n",
    "        super(EmotionClassifierWithConv, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.conv = nn.Conv1d(in_channels=768, out_channels=num_filters, kernel_size=kernel_size, padding=1)  # Adjust padding\n",
    "        self.fc = nn.Linear(num_filters, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = output.pooler_output\n",
    "        pooled_output = pooled_output.unsqueeze(2)\n",
    "        \n",
    "        conv_out = F.relu(self.conv(pooled_output))\n",
    "        pooled_conv_out, _ = torch.max(conv_out, dim=2)  \n",
    "        logits = self.fc(pooled_conv_out)\n",
    "        return logits\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:47.287327Z",
     "iopub.execute_input": "2024-05-01T17:02:47.287809Z",
     "iopub.status.idle": "2024-05-01T17:02:47.295182Z",
     "shell.execute_reply.started": "2024-05-01T17:02:47.287784Z",
     "shell.execute_reply": "2024-05-01T17:02:47.294188Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes =6  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_ids = [0, 1]  \n",
    "\n",
    "\n",
    "model = EmotionClassifierWithConv(model, num_classes)\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "num_epochs=3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "       \n",
    "        labels = labels.to(device).long()\n",
    "        outputs = outputs.float()\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = total_correct / len(train_dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    total_val_correct = 0\n",
    "    val_predicted = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            outputs = outputs.float()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val_correct += (predicted == labels).sum().item()\n",
    "            val_predicted.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:02:47.296356Z",
     "iopub.execute_input": "2024-05-01T17:02:47.296672Z",
     "iopub.status.idle": "2024-05-01T17:13:04.215823Z",
     "shell.execute_reply.started": "2024-05-01T17:02:47.296649Z",
     "shell.execute_reply": "2024-05-01T17:13:04.214713Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "val_predicted = np.array(val_predicted)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "\n",
    "report = classification_report(val_labels, val_predicted, target_names=[f'Class {i}' for i in range(num_classes)])\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:13:04.217530Z",
     "iopub.execute_input": "2024-05-01T17:13:04.218313Z",
     "iopub.status.idle": "2024-05-01T17:13:04.242809Z",
     "shell.execute_reply.started": "2024-05-01T17:13:04.218273Z",
     "shell.execute_reply": "2024-05-01T17:13:04.241850Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "Classification Report:\n              precision    recall  f1-score   support\n\n     Class 0       0.96      0.94      0.95       797\n     Class 1       0.97      0.90      0.93       821\n     Class 2       0.93      0.97      0.95       824\n     Class 3       0.93      0.96      0.95       836\n     Class 4       0.95      0.87      0.91       863\n     Class 5       0.91      1.00      0.95       859\n\n    accuracy                           0.94      5000\n   macro avg       0.94      0.94      0.94      5000\nweighted avg       0.94      0.94      0.94      5000\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'model_weights40k.pth')\n",
    "\n",
    "\n",
    "with zipfile.ZipFile('/kaggle/working/model_weights.zip', 'w') as zip_f:\n",
    "    zip_f.write('model_weights40k.pth')\n",
    "\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'model_weights.zip')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-01T17:13:04.244008Z",
     "iopub.execute_input": "2024-05-01T17:13:04.244308Z",
     "iopub.status.idle": "2024-05-01T17:13:05.939135Z",
     "shell.execute_reply.started": "2024-05-01T17:13:04.244283Z",
     "shell.execute_reply": "2024-05-01T17:13:05.938254Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "/kaggle/working/model_weights.zip",
      "text/html": "<a href='model_weights.zip' target='_blank'>model_weights.zip</a><br>"
     },
     "metadata": {}
    }
   ]
  }
 ]
}
